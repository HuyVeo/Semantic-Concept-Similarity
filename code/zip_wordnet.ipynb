{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Gộp word với gloss",
   "id": "80d7442200cf230"
  },
  {
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-10-14T14:00:48.857899Z",
     "start_time": "2025-10-14T14:00:48.717812Z"
    }
   },
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Đã gộp xong! File kết quả: D:\\Semantic-Concept-Similarity\\data\\WordNet\\WordNet.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:1: SyntaxWarning: invalid escape sequence '\\S'\n",
      "<>:2: SyntaxWarning: invalid escape sequence '\\S'\n",
      "<>:3: SyntaxWarning: invalid escape sequence '\\S'\n",
      "<>:1: SyntaxWarning: invalid escape sequence '\\S'\n",
      "<>:2: SyntaxWarning: invalid escape sequence '\\S'\n",
      "<>:3: SyntaxWarning: invalid escape sequence '\\S'\n",
      "C:\\Users\\ADMIN\\AppData\\Local\\Temp\\ipykernel_9716\\840028965.py:1: SyntaxWarning: invalid escape sequence '\\S'\n",
      "  file_words = \"D:\\Semantic-Concept-Similarity\\data\\WordNet\\Words.txt\"\n",
      "C:\\Users\\ADMIN\\AppData\\Local\\Temp\\ipykernel_9716\\840028965.py:2: SyntaxWarning: invalid escape sequence '\\S'\n",
      "  file_gloss = \"D:\\Semantic-Concept-Similarity\\data\\WordNet\\gloss_tach.txt\"\n",
      "C:\\Users\\ADMIN\\AppData\\Local\\Temp\\ipykernel_9716\\840028965.py:3: SyntaxWarning: invalid escape sequence '\\S'\n",
      "  output_file = \"D:\\Semantic-Concept-Similarity\\data\\WordNet\\WordNet.txt\"\n"
     ]
    }
   ],
   "execution_count": 2,
   "source": [
    "file_words = \"D:\\Semantic-Concept-Similarity\\data\\WordNet\\Words.txt\"\n",
    "file_gloss = \"D:\\Semantic-Concept-Similarity\\data\\WordNet\\gloss_tach.txt\"\n",
    "output_file = \"D:\\Semantic-Concept-Similarity\\data\\WordNet\\WordNet.txt\"\n",
    "\n",
    "\n",
    "with open(file_words, \"r\", encoding=\"utf-8\") as f1, open(file_gloss, \"r\", encoding=\"utf-8\") as f2:\n",
    "    words = f1.readlines()\n",
    "    glosses = f2.readlines()\n",
    "\n",
    "\n",
    "merged_lines = []\n",
    "for w, g in zip(words, glosses):\n",
    "    merged_lines.append(f\"{w.strip()}\\t{g.strip()}\\n\")\n",
    "\n",
    "\n",
    "with open(output_file, \"w\", encoding=\"utf-8\") as out:\n",
    "    out.writelines(merged_lines)\n",
    "\n",
    "print(\"Đã gộp xong! File kết quả:\", output_file)\n"
   ],
   "id": "initial_id"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Truy vấn list word Vsim-400 vào kho tri thứ WordNet",
   "id": "18b22665e9d57209"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-14T16:00:34.748626Z",
     "start_time": "2025-10-14T16:00:34.601743Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "\n",
    "# ====== Cấu hình file ======\n",
    "Word_Net = r\"D:\\Semantic-Concept-Similarity\\data\\WordNet\\WordNet.txt\"\n",
    "Word_list = r\"D:\\Semantic-Concept-Similarity\\data\\WordNet\\words_list.txt\"\n",
    "output = r\"D:\\Semantic-Concept-Similarity\\data\\WordNet\\WordNet_Definitions.txt\"\n",
    "\n",
    "# ====== Kiểm tra file tồn tại ======\n",
    "for f in [Word_Net, Word_list]:\n",
    "    if not os.path.exists(f):\n",
    "        print(f\"⚠️ Không tìm thấy file: {f}\")\n",
    "        exit()\n",
    "\n",
    "# ====== Đọc danh sách từ cần lọc (theo thứ tự gốc) ======\n",
    "with open(Word_list, \"r\", encoding=\"utf-8\") as f:\n",
    "    target_words = [line.strip() for line in f if line.strip()]\n",
    "\n",
    "# ====== Đọc file merged.txt thành dict ======\n",
    "word_to_gloss = {}\n",
    "\n",
    "with open(Word_Net, \"r\", encoding=\"utf-8\") as f:\n",
    "    for line in f:\n",
    "        if not line.strip():\n",
    "            continue\n",
    "        parts = line.strip().split(\"\\t\", 1)\n",
    "        if len(parts) == 2:\n",
    "            word, gloss = parts\n",
    "        else:\n",
    "            # Nếu dòng không có gloss, gán gloss rỗng\n",
    "            word, gloss = parts[0], \"[]\"\n",
    "        word_to_gloss[word.lower()] = gloss\n",
    "\n",
    "# ====== Tạo output giữ nguyên thứ tự ======\n",
    "filtered_lines = []\n",
    "for word in target_words:\n",
    "    gloss = word_to_gloss.get(word.lower(), \"[]\")  # Nếu không có gloss thì []\n",
    "    filtered_lines.append(f\"{word}\\t{gloss}\\n\")\n",
    "\n",
    "# ====== Ghi kết quả ======\n",
    "with open(output, \"w\", encoding=\"utf-8\") as f:\n",
    "    f.writelines(filtered_lines)\n",
    "\n",
    "print(f\" Đã trích xuất {len(filtered_lines)} từ (theo đúng thứ tự). File lưu tại: {output}\")\n"
   ],
   "id": "37a176cc95d14e1",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Đã trích xuất 800 từ (theo đúng thứ tự). File lưu tại: D:\\Semantic-Concept-Similarity\\data\\WordNet\\WordNet_Definitions.txt\n"
     ]
    }
   ],
   "execution_count": 1
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
